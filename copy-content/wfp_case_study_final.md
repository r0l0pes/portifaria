# PORTFOLIO VERSION

## AI-Powered Agricultural Extension for Low-Literacy Farmers
**World Food Programme Innovation Accelerator** | Mar 2024 – Dec 2025 | Munich, Germany

*Designed and executed pilot of generative AI voice agent for 5,000 farmers in Tanzania; demonstrated 60% cost efficiency potential vs. human-led outreach; presented strategic recommendations for scaling AI products across 20+ country programs.*

---

### CONTEXT

The World Food Programme Innovation Accelerator operates as a grant-funded sprint program for rapid validation of emerging technologies across humanitarian operations. In partnership with Viamo, an external voice technology vendor, WFP sought to test whether generative AI could deliver agricultural advice to low-literacy farmers in Tanzania—a population facing severe constraints: limited smartphone literacy, unreliable connectivity, and languages underrepresented in commercial AI training data.

The stakes: WFP's agricultural programs operate in 20+ countries with traditional extension worker models costing 3–5× more per farmer reached. A scalable AI alternative could fundamentally reshape service delivery, but only if the technology proved viable in extreme conditions and the organization could responsibly govern AI adoption at scale.

---

### PROBLEM

**Challenge 1: Uncertain product-market fit in extreme constraints**  
Standard AI voice interfaces assume reliable connectivity, smartphone literacy, and well-resourced training data. None of these held true for Tanzanian smallholder farmers. The product hypothesis—that generative AI could replace human extension workers—needed validation before WFP committed to scaling.

**Challenge 2: No clear success framework**  
WFP's Innovation Accelerator structure meant speed over perfection, but without defined metrics for "successful validation," the pilot risked producing anecdotal findings rather than strategic clarity. The organization needed a defensible recommendation: invest, iterate, or exit.

**Challenge 3: Organizational AI readiness**  
Beyond this single pilot, WFP faced a broader question: how should a humanitarian organization adopt AI responsibly, at scale, when most staff lack technical backgrounds? The answer required more than one proof-of-concept.

---

### ROLE & SCOPE

**Ownership**: WFP-side product manager for Viamo partnership validation; contributor to internal AI experimentation platform roadmap.

**In scope**:
- Define success metrics for pilot (adoption, retention, decision quality)
- Coordinate cross-functional execution across WFP field operations and Viamo engineering
- Design analytics framework to measure user behavior and AI interface usability
- Translate pilot outcomes into strategic recommendations for Innovation Accelerator leadership
- Support AI Sandbox product roadmap prioritization and governance framework development

**Out of scope**:  
Direct management of engineering teams (Viamo was external vendor); large-scale deployment (pilot was validation-only); policy-level AI governance (contributed input, not decision authority).

**Stakeholders**: WFP Innovation Accelerator leadership, Tanzania country program teams, Viamo engineering and product teams, internal AI Sandbox users (non-technical humanitarian staff testing Machine Learning and Generative AI use cases).

---

### APPROACH

**1. Defined defensible success metrics upfront**  
Structured validation around three measurable dimensions:
- **Adoption**: Did farmers engage beyond initial curiosity? (Target: 40%+ weekly active usage)
- **Retention**: Did value persist over growing season? (Target: 60%+ return users at 8 weeks)
- **Decision quality**: Did advice improve farming outcomes vs. control group? (Measured via harvest yield proxies, self-reported behavior change)

Trade-off: Prioritized behavioral signals over perfect outcome measurement—harvest cycles extend beyond pilot timeline, so retention and reported behavior served as leading indicators.

**2. Built lightweight analytics infrastructure for low-connectivity environment**  
Implemented tracking framework adapted for intermittent connectivity:
- Call completion rates and session duration as proxy for engagement
- Sentiment analysis on voice feedback (Viamo's NLP stack)
- Manual surveys with field staff for qualitative depth

Trade-off: Accepted lower statistical confidence (5,000 farmers, not 50,000) in exchange for faster cycle time and cost constraints of grant-funded validation.

**3. Ran parallel learning stream on organizational AI adoption**  
While managing Viamo validation, contributed to WFP's AI Sandbox—an internal platform enabling non-technical staff to test Machine Learning and Generative AI use cases without engineering dependencies. Focused on:
- Use case validation methodology (how to test AI hypotheses quickly)
- Governance framework inputs (responsible AI for vulnerable populations)
- Roadmap prioritization (which internal use cases merited investment)

Trade-off: Balanced depth on single pilot vs. breadth across organizational AI readiness; chose breadth to demonstrate strategic thinking beyond execution.

**4. Coordinated distributed stakeholders without formal authority**  
Managed weekly syncs across WFP field operations (Tanzania), Viamo engineering (remote), and Innovation Accelerator leadership. Navigated misaligned incentives:
- Field teams prioritized farmer outcomes over tech validation
- Viamo optimized for product showcase vs. rigorous testing
- Leadership needed investment decision clarity, not incremental progress updates

Approach: Translated each stakeholder's goals into shared success criteria; used data (early adoption curves, cost models) to build alignment.

**5. Designed strategic recommendation framework, not just pilot report**  
Structured final presentation around three decision paths:
- **Scale now**: Conditions required (technical maturity, cost model, risk mitigation)
- **Iterate**: Specific hypotheses to test before scaling (e.g., expand language coverage, test different delivery models)
- **Pivot/exit**: Criteria that would invalidate the approach

Presented findings to Innovation Accelerator leadership with explicit trade-offs, cost implications, and applicability across WFP's 20+ country agricultural portfolio.

---

### RESULTS

**Pilot validation outcomes:**
- Engaged 5,000 farmers across 6-month growing season in Tanzania (sunflower farmers, Northern and Southern highlands)
- Demonstrated 60% cost efficiency potential vs. traditional extension worker model (based on cost-per-farmer-reached analysis)
- Identified 3 critical failure modes for AI voice in low-literacy contexts (connectivity dropoffs, dialect coverage gaps, trust calibration with AI-generated advice)

**Strategic impact:**
- Informed WFP's decision framework for AI product investments across 20+ country programs
- Contributed to governance framework development for responsible AI adoption in humanitarian operations
- Provided reusable validation playbook for Innovation Accelerator's future technology pilots

**Organizational learning:**
- Established analytics methodology for measuring AI product success in resource-constrained environments
- Validated (and invalidated) assumptions about generative AI readiness for extreme user populations—findings applicable beyond agriculture to health, nutrition, cash assistance programs

**What didn't work:**  
Initial adoption tracking relied too heavily on digital metrics (call logs, session duration) when field observations revealed farmers sharing phones, making individual-level tracking misleading. Pivoted mid-pilot to combine quantitative signals with qualitative field surveys conducted by WFP agricultural extension staff.

---

**Word count: ~975 words (portfolio section only)**
